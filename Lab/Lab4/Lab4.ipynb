{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c597700",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Arial', sans-serif; font-size: 3rem; color: #6a1b9a; text-align: center; margin: 0; \n",
    "           text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1); background-color: #f5f5f5; padding: 10px; \n",
    "           border-radius: 10px; border: 4px solid #6a5acd; box-shadow: 2px 2px 12px rgba(0, 0, 0, 0.1); width: 97%;\">\n",
    "    <span style=\"font-weight: bold; color: #6a1b9a; animation: pulse 2s infinite;\"></span>COMPX310-2025 Lab 4 <br> ROC Curves and Model Evaluation (Wisconsin Breast Cancer)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa86f72",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTwkadoBZLAFafSH9pQuwSx3EQTi8AwowI7TA&s\" width=\"500\" height=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0cad2e",
   "metadata": {},
   "source": [
    "## Lab Information\n",
    "- **Due Date:** October 19, 2025\n",
    "- **Weight:** 3% of total course grade\n",
    "- **Platform:** Google Colab, Kaggle, or VSCode (with Jupyter extension)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08bd15",
   "metadata": {},
   "source": [
    "## Student Information\n",
    "**Please fill in your details:**\n",
    "- **Name:** Guo Zimo \n",
    "- **Student ID:** 20233006327\n",
    "- **Partner's Name (if applicable):** [Partner's Name]\n",
    "- **Partner's Student ID (if applicable):** [Partner's ID]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac12de4",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "### Learning Objectives\n",
    "In this lab, you will:\n",
    "1. Understand how to prepare and interpret ROC curves\n",
    "2. Evaluate classifiers using multiple metrics (accuracy, AUC, precision, recall)\n",
    "3. Apply cross-validation for robust model evaluation\n",
    "4. Compare model performance on different test datasets\n",
    "5. Understand why models may perform differently on different datasets\n",
    "\n",
    "### What is an ROC Curve?\n",
    "- **ROC** stands for Receiver Operating Characteristic\n",
    "- It plots **True Positive Rate (TPR)** vs **False Positive Rate (FPR)** at various threshold settings\n",
    "- **AUC (Area Under Curve)** measures the overall performance - higher is better\n",
    "- A perfect classifier has AUC = 1.0, random guessing has AUC = 0.5\n",
    "\n",
    "### Dataset\n",
    "We'll use the Wisconsin Breast Cancer dataset to classify tumors as benign or malignant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f4dcc",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://i-blog.csdnimg.cn/blog_migrate/c664f6e8d228443c41717bbbbb8eabe9.png\" width=\"600\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf9a3d",
   "metadata": {},
   "source": [
    "## Part A: ROC Curves and Cross-Validation Evaluation [2 marks]\n",
    "\n",
    "### Task Overview\n",
    "1. Load and prepare the breast cancer dataset\n",
    "2. Use 10-fold cross-validation to evaluate two classifiers:\n",
    "   - **SGDClassifier** (Stochastic Gradient Descent)\n",
    "   - **GaussianNB** (Gaussian Naive Bayes)\n",
    "3. Generate ROC curves and calculate AUC values\n",
    "4. Compare classifiers using multiple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e37955",
   "metadata": {},
   "source": [
    "### Task 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f10f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "✓ Random seed set to: 6327\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (roc_curve, auc, classification_report, \n",
    "                            confusion_matrix, accuracy_score)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "\n",
    "# Set your student ID for reproducibility\n",
    "# COMPLETE: If working in pairs, use the larger student ID\n",
    "STUDENT_ID = 6327 # COMPLETE: Enter your student ID\n",
    "\n",
    "print(f\"✓ Random seed set to: {STUDENT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53b6848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded successfully!\n",
      "Dataset shape: (699, 11)\n",
      "\n",
      "First 5 rows:\n",
      "<bound method NDFrame.head of           id  thickness  size  shape  adhesion  single nuclei  chromatin  \\\n",
      "0    1000025          5     1      1         1       2      1          3   \n",
      "1    1002945          5     4      4         5       7     10          3   \n",
      "2    1015425          3     1      1         1       2      2          3   \n",
      "3    1016277          6     8      8         1       3      4          3   \n",
      "4    1017023          4     1      1         3       2      1          3   \n",
      "..       ...        ...   ...    ...       ...     ...    ...        ...   \n",
      "694   776715          3     1      1         1       3      2          1   \n",
      "695   841769          2     1      1         1       2      1          1   \n",
      "696   888820          5    10     10         3       7      3          8   \n",
      "697   897471          4     8      6         4       3      4         10   \n",
      "698   897471          4     8      8         5       4      5         10   \n",
      "\n",
      "     nucleoli  mitosis  class  \n",
      "0           1        1      0  \n",
      "1           2        1      0  \n",
      "2           1        1      0  \n",
      "3           7        1      0  \n",
      "4           1        1      0  \n",
      "..        ...      ...    ...  \n",
      "694         1        1      0  \n",
      "695         1        1      0  \n",
      "696        10        2      1  \n",
      "697         6        1      1  \n",
      "698         4        1      1  \n",
      "\n",
      "[699 rows x 11 columns]>\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE: Load the dataset\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n",
    "\n",
    "print(\"✓ Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head)\n",
    "# COMPLETE: Display first 5 rows using .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8220d",
   "metadata": {},
   "source": [
    "### Task 2: Data Cleaning and Preparation\n",
    "\n",
    "**What to do:**\n",
    "1. Check for missing values\n",
    "2. Handle missing values appropriately\n",
    "3. Remove the 'ID' column (not useful for prediction)\n",
    "4. Separate features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cccd2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "\n",
      "Missing values per column:\n",
      "id            0\n",
      "thickness     0\n",
      "size          0\n",
      "shape         0\n",
      "adhesion      0\n",
      "single        0\n",
      "nuclei       16\n",
      "chromatin     0\n",
      "nucleoli      0\n",
      "mitosis       0\n",
      "class         0\n",
      "dtype: int64\n",
      "\n",
      "Target variable unique values: [0 1]\n",
      "Class distribution:\n",
      "class\n",
      "0    458\n",
      "1    241\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check dataset information\n",
    "print(\"Dataset Information:\")\n",
    "# print(df.info)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "df = df.replace(\"#NUM!\", pd.NA, inplace=False)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nTarget variable unique values: {df['class'].unique()}\")\n",
    "print(f\"Class distribution:\\n{df['class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fdd19ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data cleaned! Shape after cleaning: (699, 10)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "# COMPLETE: Replace '?' with NaN if present, then drop rows with missing values\n",
    "df = df.replace(pd.NA, \"?\")\n",
    "df = df.drop(\"nuclei\", axis=1)\n",
    "\n",
    "print(f\"✓ Data cleaned! Shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fda9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (699, 8)\n",
      "Target shape: (699,)\n",
      "\n",
      "Feature columns: ['thickness', 'size', 'shape', 'adhesion', 'single', 'chromatin', 'nucleoli', 'mitosis']\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "df = df.drop(\"id\", axis=1)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed21da7",
   "metadata": {},
   "source": [
    "### Task 3: Train-Test Split\n",
    "\n",
    "Split the data into 80% training and 20% testing sets.\n",
    "**Important:** Use `stratify=y` to maintain class proportions in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8c83bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data split completed!\n",
      "Training set size: 559\n",
      "Test set size: 140\n",
      "Training class distribution:\n",
      "class\n",
      "0    366\n",
      "1    193\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE: Split the data using train_test_split\n",
    "# Parameters: test_size=0.2, random_state=STUDENT_ID, stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=STUDENT_ID)\n",
    "\n",
    "print(\"✓ Data split completed!\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Training class distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a3e04",
   "metadata": {},
   "source": [
    "### Task 4a: 10-Fold Cross-Validation Predictions\n",
    "\n",
    "Use `cross_val_predict` to generate predictions for both classifiers:\n",
    "- **SGDClassifier**: Use `method='decision_function'` to get decision scores\n",
    "- **GaussianNB**: Use `method='predict_proba'` to get probability scores\n",
    "\n",
    "**Why Cross-Validation?**\n",
    "Cross-validation gives us a more reliable estimate of model performance by testing on multiple different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce89a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Classifiers initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "# COMPLETE: Create SGDClassifier with random_state=STUDENT_ID, loss='log_loss'\n",
    "sgd_clf = SGDClassifier(random_state=STUDENT_ID, loss=\"log_loss\")\n",
    "\n",
    "# COMPLETE: Create GaussianNB classifier\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "print(\"✓ Classifiers initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f969b37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SGD cross-validation scores obtained: (699,)\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE: Get cross-validation predictions for SGDClassifier\n",
    "# Hint: Use cross_val_predict with cv=10, method='decision_function'\n",
    "\n",
    "sgd_y_scores = cross_val_predict(sgd_clf, X=X, y=y, cv=10, method=\"decision_function\")\n",
    "\n",
    "print(f\"✓ SGD cross-validation scores obtained: {sgd_y_scores.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a11e465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Naive Bayes cross-validation scores obtained: (699,)\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE: Get cross-validation predictions for GaussianNB\n",
    "# Hint: Use cross_val_predict with cv=10, method='predict_proba'\n",
    "# Note: predict_proba returns 2 columns, use the second column [:, 1]\n",
    "\n",
    "nb_y_scores_proba = cross_val_predict(nb_clf, X=X, y=y, cv=10, method=\"predict_proba\") # COMPLETE: Use cross_val_predict with NB classifier\n",
    "nb_y_scores = nb_y_scores_proba[:, 1] # COMPLETE: Extract second column for positive class probabilities\n",
    "\n",
    "print(f\"✓ Naive Bayes cross-validation scores obtained: {nb_y_scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510dbc6",
   "metadata": {},
   "source": [
    "### Task 4b: Plot ROC Curves with AUC Values\n",
    "\n",
    "**Requirements:**\n",
    "1. Calculate ROC curve (FPR, TPR) for both classifiers\n",
    "2. Calculate AUC (Area Under Curve) for both\n",
    "3. Plot both ROC curves on the same figure\n",
    "4. Add a diagonal line from (0,0) to (1,1) representing random guessing\n",
    "5. Include legend with classifier names and AUC values\n",
    "6. Add descriptive title and axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba34b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Calculate ROC curve for SGDClassifier\n",
    "# Hint: Use roc_curve(Actual, predicted)\n",
    "\n",
    "sgd_fpr, sgd_tpr, sgd_thresholds = # COMPLETE: Calculate ROC curve for SGD\n",
    "sgd_auc = # COMPLETE: Calculate AUC using sgd_fpr and sgd_tpr\n",
    "\n",
    "print(f\"SGD AUC: {sgd_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1df529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Calculate ROC curve for GaussianNB\n",
    "# Hint: Use roc_curve(Actual, predicted)\n",
    "\n",
    "nb_fpr, nb_tpr, nb_thresholds = # COMPLETE: Calculate ROC curve for NB\n",
    "nb_auc = # COMPLETE: Calculate AUC using nb_fpr and nb_tpr\n",
    "\n",
    "print(f\"Naive Bayes AUC: {nb_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0046199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Plot ROC curves for both classifiers\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# COMPLETE: Plot SGD ROC curve\n",
    "# Hint: plt.plot(sgd_fpr, sgd_tpr, label=f'SGD (AUC = {sgd_auc:.4f})', linewidth=2)\n",
    "\n",
    "# COMPLETE: Plot Naive Bayes ROC curve\n",
    "# Hint: plt.plot(nb_fpr, nb_tpr, label=f'Naive Bayes (AUC = {nb_auc:.4f})', linewidth=2)\n",
    "\n",
    "# COMPLETE: Plot diagonal line (random classifier)\n",
    "# Hint: plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier (AUC = 0.5)')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: SGDClassifier vs Gaussian Naive Bayes (10-Fold CV)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ ROC curves plotted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Optional: Zoomed ROC Curve (Top-Left Corner)\n",
    "\n",
    "Sometimes ROC curves are very close together. Zooming into the top-left corner can help distinguish them better.\n",
    "\"\"\"\n",
    "\n",
    "# Cell 21: Code\n",
    "# Optional: Zoom to top-left corner\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# COMPLETE: Plot the same ROC curves as above\n",
    "\n",
    "# COMPLETE: Add zoom limits\n",
    "plt.xlim([0, 0.15])\n",
    "plt.ylim([0.85, 1])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (Zoomed) - Top-Left Corner')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec896db",
   "metadata": {},
   "source": [
    "### Task 4c: Cross-Validation Accuracy and Classification Reports\n",
    "\n",
    "Calculate:\n",
    "1. Cross-validation accuracy using `cross_val_score`\n",
    "2. Classification report for both classifiers\n",
    "3. Confusion matrix for both classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053eb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Calculate cross-validation accuracy for SGDClassifier\n",
    "# Hint: Use cross_val_score with cv=10, scoring='accuracy'\n",
    "\n",
    "sgd_cv_scores = # COMPLETE: cross_val_score(sgd_clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "sgd_cv_accuracy = # COMPLETE: Calculate mean of cv scores\n",
    "\n",
    "print(f\"SGD Cross-Validation Accuracy: {sgd_cv_accuracy:.4f} (+/- {sgd_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Calculate cross-validation accuracy for GaussianNB\n",
    "\n",
    "nb_cv_scores = # COMPLETE: cross_val_score for Naive Bayes\n",
    "nb_cv_accuracy = # COMPLETE: Calculate mean\n",
    "\n",
    "print(f\"Naive Bayes Cross-Validation Accuracy: {nb_cv_accuracy:.4f} (+/- {nb_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Get predictions for classification report and confusion matrix\n",
    "# Hint: Use cross_val_predict with cv=10 (no method parameter, default is 'predict')\n",
    "\n",
    "sgd_y_pred = # COMPLETE: cross_val_predict for SGD\n",
    "nb_y_pred = # COMPLETE: cross_val_predict for Naive Bayes\n",
    "\n",
    "print(\"✓ Predictions obtained for classification reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0473829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report and Confusion Matrix for SGDClassifier\n",
    "print(\"=\"*60)\n",
    "print(\"SGDClassifier - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "# COMPLETE: Print classification report\n",
    "# Hint: classification_report(actual, predicted)\n",
    "\n",
    "print(\"\\nSGDClassifier - Confusion Matrix\")\n",
    "sgd_cm = # COMPLETE: confusion_matrix(actual, predicted)\n",
    "print(sgd_cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# COMPLETE: Use sns.heatmap to visualize confusion matrix\n",
    "# Hint: sns.heatmap(sgd_cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.title('SGDClassifier - Confusion Matrix (10-Fold CV)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report and Confusion Matrix for GaussianNB\n",
    "print(\"=\"*60)\n",
    "print(\"Gaussian Naive Bayes - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "# COMPLETE: Print classification report for Naive Bayes\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes - Confusion Matrix\")\n",
    "nb_cm = # COMPLETE: confusion_matrix for Naive Bayes\n",
    "print(nb_cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# COMPLETE: Use sns.heatmap to visualize confusion matrix\n",
    "\n",
    "plt.title('Gaussian Naive Bayes - Confusion Matrix (10-Fold CV)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b46d26",
   "metadata": {},
   "source": [
    "### Task 4d: Train on Full Training Set and Evaluate on Test Set\n",
    "\n",
    "Now train both classifiers on the **full training set** and evaluate on the **test set**.\n",
    "Compare these results with the cross-validation results from parts b) and c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d36fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Train SGDClassifier on full training data\n",
    "# Hint: sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train SGD\n",
    "# COMPLETE: Fit the model\n",
    "\n",
    "# Get predictions and scores for test set\n",
    "sgd_test_pred = # COMPLETE: Use .predict(X_test)\n",
    "sgd_test_scores = # COMPLETE: Use .decision_function(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "sgd_test_accuracy = # COMPLETE: accuracy_score(y_test, sgd_test_pred)\n",
    "\n",
    "# Calculate AUC\n",
    "sgd_test_fpr, sgd_test_tpr, _ = # COMPLETE: roc_curve(y_test, sgd_test_scores)\n",
    "sgd_test_auc = # COMPLETE: auc(sgd_test_fpr, sgd_test_tpr)\n",
    "\n",
    "print(f\"SGD Test Set Accuracy: {sgd_test_accuracy:.4f}\")\n",
    "print(f\"SGD Test Set AUC: {sgd_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86491340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Train GaussianNB on full training data\n",
    "\n",
    "# Train Naive Bayes\n",
    "# COMPLETE: Fit the model\n",
    "\n",
    "# Get predictions and scores for test set\n",
    "nb_test_pred = # COMPLETE: Use .predict(X_test)\n",
    "nb_test_proba = # COMPLETE: Use .predict_proba(X_test)\n",
    "nb_test_scores = # COMPLETE: Extract second column [:, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "nb_test_accuracy = # COMPLETE: accuracy_score(y_test, nb_test_pred)\n",
    "\n",
    "# Calculate AUC\n",
    "nb_test_fpr, nb_test_tpr, _ = # COMPLETE: roc_curve(y_test, nb_test_scores)\n",
    "nb_test_auc = # COMPLETE: auc(nb_test_fpr, nb_test_tpr)\n",
    "\n",
    "print(f\"Naive Bayes Test Set Accuracy: {nb_test_accuracy:.4f}\")\n",
    "print(f\"Naive Bayes Test Set AUC: {nb_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Cross-Validation vs Test Set Results\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARISON: Cross-Validation vs Test Set Performance\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSGDClassifier:\")\n",
    "print(f\"  CV Accuracy:   {sgd_cv_accuracy:.4f}\")\n",
    "print(f\"  Test Accuracy: {sgd_test_accuracy:.4f}\")\n",
    "print(f\"  Difference:    {abs(sgd_cv_accuracy - sgd_test_accuracy):.4f}\")\n",
    "print(f\"\\n  CV AUC:        {sgd_auc:.4f}\")\n",
    "print(f\"  Test AUC:      {sgd_test_auc:.4f}\")\n",
    "print(f\"  Difference:    {abs(sgd_auc - sgd_test_auc):.4f}\")\n",
    "\n",
    "print(f\"\\nGaussian Naive Bayes:\")\n",
    "print(f\"  CV Accuracy:   {nb_cv_accuracy:.4f}\")\n",
    "print(f\"  Test Accuracy: {nb_test_accuracy:.4f}\")\n",
    "print(f\"  Difference:    {abs(nb_cv_accuracy - nb_test_accuracy):.4f}\")\n",
    "print(f\"\\n  CV AUC:        {nb_auc:.4f}\")\n",
    "print(f\"  Test AUC:      {nb_test_auc:.4f}\")\n",
    "print(f\"  Difference:    {abs(nb_auc - nb_test_auc):.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7319b",
   "metadata": {},
   "source": [
    "### Discussion Questions for Part A\n",
    "\n",
    "**Answer the following questions in markdown cells:**\n",
    "\n",
    "1. **Which classifier would you prefer, and why?**\n",
    "   - [Your answer here]\n",
    "   \n",
    "2. **Is the classifier with the better AUC value also the more accurate classifier?**\n",
    "   - [Your answer here]\n",
    "   \n",
    "3. **Looking at the precision and recall values in the classification reports, what conclusions can you draw?**\n",
    "   - [Your answer here]\n",
    "   \n",
    "4. **Are the test set values reasonably close to the cross-validation estimates? Why or why not?**\n",
    "   - [Your answer here]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedc27a",
   "metadata": {},
   "source": [
    "## Part B: Evaluating Performance on Two Test Datasets [1 mark]\n",
    "\n",
    "### Background\n",
    "We have two additional test datasets from different hospitals:\n",
    "1. **Minnesota Hospital Dataset**\n",
    "2. **Melbourne Hospital Dataset**\n",
    "\n",
    "### Task Overview\n",
    "1. Use one of the trained classifiers from Part A\n",
    "2. Evaluate on both new test datasets\n",
    "3. Compare results and identify differences\n",
    "4. Suggest solutions if performance differs significantly\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ea127",
   "metadata": {},
   "source": [
    "### Task 1: Load the Two New Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minnesota hospital dataset provided in the folder ('test_dataset_minnesota').\n",
    "df_minnesota = # COMPLETE\n",
    "\n",
    "print(f\"Minnesota dataset shape: {df_minnesota.shape}\")\n",
    "print(f\"Minnesota first 5 rows:\")\n",
    "# COMPLETE: Display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e881479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Melbourne hospital dataset provided in the folder ('test_dataset_melbourne').\n",
    "\n",
    "df_melbourne = # COMPLETE\n",
    "\n",
    "print(f\"Melbourne dataset shape: {df_melbourne.shape}\")\n",
    "print(f\"Melbourne first 5 rows:\")\n",
    "# COMPLETE: Display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1700bc8",
   "metadata": {},
   "source": [
    "### Task 2: Prepare Features and Target for Both Datasets\n",
    "\n",
    "Apply the same preprocessing as the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a865ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Prepare Minnesota data\n",
    "# Handle missing values if any, then separate X and y\n",
    "\n",
    "# COMPLETE: Clean and prepare features\n",
    "X_minnesota = # COMPLETE\n",
    "y_minnesota = # COMPLETE\n",
    "\n",
    "print(f\"Minnesota - X shape: {X_minnesota.shape}, y shape: {y_minnesota.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Prepare Melbourne data\n",
    "# Handle missing values if any, then separate X and y\n",
    "\n",
    "# COMPLETE: Clean and prepare features\n",
    "X_melbourne = # COMPLETE\n",
    "y_melbourne = # COMPLETE\n",
    "\n",
    "print(f\"Melbourne - X shape: {X_melbourne.shape}, y shape: {y_melbourne.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a94b81",
   "metadata": {},
   "source": [
    "### Task 3: Train Model on Full Original Dataset\n",
    "\n",
    "Train your chosen classifier (SGD or Naive Bayes) on the **complete original dataset** (combine train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Combine original training and test data\n",
    "X_full = # COMPLETE: Concatenate X_train and X_test\n",
    "y_full = # COMPLETE: Concatenate y_train and y_test\n",
    "\n",
    "print(f\"Full dataset shape: {X_full.shape}\")\n",
    "\n",
    "# COMPLETE: Choose one classifier and train on full data\n",
    "# For example, using SGDClassifier:\n",
    "final_clf = # COMPLETE: Create your chosen classifier\n",
    "# COMPLETE: Fit on X_full, y_full\n",
    "\n",
    "print(\"✓ Model trained on full original dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c47526",
   "metadata": {},
   "source": [
    "### Task 4: Evaluate on Minnesota Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc46739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Get predictions and scores for Minnesota dataset\n",
    "# Hint: Use .predict() and .decision_function() or .predict_proba()\n",
    "\n",
    "minnesota_pred = # COMPLETE: Get predictions\n",
    "minnesota_scores = # COMPLETE: Get decision scores or probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "minnesota_accuracy = # COMPLETE: Calculate accuracy\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "minnesota_fpr, minnesota_tpr, _ = # COMPLETE: Calculate ROC curve\n",
    "minnesota_auc = # COMPLETE: Calculate AUC\n",
    "\n",
    "print(f\"Minnesota Dataset:\")\n",
    "print(f\"  Accuracy: {minnesota_accuracy:.4f}\")\n",
    "print(f\"  AUC: {minnesota_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Classification report for Minnesota\n",
    "print(\"Minnesota Dataset - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "# COMPLETE: Print classification report\n",
    "\n",
    "# COMPLETE: Confusion matrix\n",
    "minnesota_cm = # COMPLETE: Calculate confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(minnesota_cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# COMPLETE: Create heatmap for confusion matrix\n",
    "\n",
    "plt.title('Minnesota Dataset - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bca08c",
   "metadata": {},
   "source": [
    "### Task 5: Evaluate on Melbourne Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e31bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Get predictions and scores for Melbourne dataset\n",
    "\n",
    "melbourne_pred = # COMPLETE: Get predictions\n",
    "melbourne_scores = # COMPLETE: Get decision scores or probabilities\n",
    "\n",
    "# Calculate accuracy\n",
    "melbourne_accuracy = # COMPLETE: Calculate accuracy\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "melbourne_fpr, melbourne_tpr, _ = # COMPLETE: Calculate ROC curve\n",
    "melbourne_auc = # COMPLETE: Calculate AUC\n",
    "\n",
    "print(f\"Melbourne Dataset:\")\n",
    "print(f\"  Accuracy: {melbourne_accuracy:.4f}\")\n",
    "print(f\"  AUC: {melbourne_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Classification report for Melbourne\n",
    "print(\"Melbourne Dataset - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "# COMPLETE: Print classification report\n",
    "\n",
    "# COMPLETE: Confusion matrix\n",
    "melbourne_cm = # COMPLETE: Calculate confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(melbourne_cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# COMPLETE: Create heatmap for confusion matrix\n",
    "\n",
    "plt.title('Melbourne Dataset - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a20ae",
   "metadata": {},
   "source": [
    "### Task 6: Compare ROC Curves for Both New Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Plot ROC curves for both new datasets\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# COMPLETE: Plot Minnesota ROC curve\n",
    "# COMPLETE: Plot Melbourne ROC curve\n",
    "# COMPLETE: Plot diagonal line\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: Minnesota vs Melbourne Datasets')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE COMPARISON ACROSS DATASETS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original Test Set:\")\n",
    "print(f\"  Accuracy: {sgd_test_accuracy:.4f}\")  # Or nb_test_accuracy if using NB\n",
    "print(f\"  AUC:      {sgd_test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nMinnesota Dataset:\")\n",
    "print(f\"  Accuracy: {minnesota_accuracy:.4f}\")\n",
    "print(f\"  AUC:      {minnesota_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nMelbourne Dataset:\")\n",
    "print(f\"  Accuracy: {melbourne_accuracy:.4f}\")\n",
    "print(f\"  AUC:      {melbourne_auc:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b506f3",
   "metadata": {},
   "source": [
    "## Discussion Questions for Part B\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "1. **Do the Minnesota and Melbourne datasets give similar results to the original test set?**\n",
    "   - [Your answer here]\n",
    "\n",
    "2. **If results differ, provide plausible reasons why (Hint: look at the dataset names/sources)**\n",
    "   - [Your answer here]\n",
    "\n",
    "3. **What could we do to improve performance if the model doesn't generalize well?**\n",
    "   - Hint: Consider:\n",
    "     - Feature selection (simpler models)\n",
    "     - Regularization\n",
    "     - Collecting more diverse training data\n",
    "     - Domain adaptation techniques\n",
    "   - [Your answer here]\n",
    "\n",
    "4. **If collecting more data is not an option, what alternatives exist?**\n",
    "   - Hint: Look at chapters 3 and 4 of your textbook\n",
    "   - Consider: regularization parameters (alpha for Ridge/Lasso, penalty for SGD)\n",
    "   - [Your answer here]\n",
    "\n",
    "5. **Optional Challenge: Did you try creating a simpler model with fewer features or stronger regularization? What were the results?**\n",
    "   - [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd70c8",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure you have:\n",
    "- [ ] Filled in your name and student ID (and partner's if applicable)\n",
    "- [ ] Completed all COMPLETE sections in the code\n",
    "- [ ] Run all code cells successfully\n",
    "- [ ] Generated all required plots (ROC curves, confusion matrices)\n",
    "- [ ] Answered all discussion questions in markdown cells\n",
    "- [ ] Verified all outputs are visible and correct\n",
    "- [ ] Used your student ID as random_state where required\n",
    "- [ ] Converted notebook to HTML\n",
    "- [ ] Checked that the HTML displays all outputs correctly\n",
    "- [ ] Submitted the HTML file to Canvas before the deadline\n",
    "\n",
    "**Remember:** If working in pairs, both students must submit the same HTML!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc36958",
   "metadata": {},
   "source": [
    "## Additional Notes\n",
    "\n",
    "### Key Concepts to Understand:\n",
    "- **ROC Curve**: Shows trade-off between true positive rate and false positive rate\n",
    "- **AUC**: Overall measure of classifier performance (0.5 = random, 1.0 = perfect)\n",
    "- **Cross-Validation**: Provides more reliable performance estimates\n",
    "- **Generalization**: Model's ability to perform well on unseen data\n",
    "- **Domain Shift**: When test data comes from different distribution than training data\n",
    "\n",
    "### Common Pitfalls to Avoid:\n",
    "- Forgetting to use random_state in classifiers and splits\n",
    "- Using wrong column for predict_proba (remember to use [:, 1])\n",
    "- Not handling missing values before evaluation\n",
    "- Comparing classifiers without considering multiple metrics\n",
    "\n",
    "**Good luck!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
