{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13a373c",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Arial', sans-serif; font-size: 3rem; color: #6a1b9a; text-align: center; margin: 0; \n",
    "           text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1); background-color: #f5f5f5; padding: 10px; \n",
    "           border-radius: 10px; border: 4px solid #6a5acd; box-shadow: 2px 2px 12px rgba(0, 0, 0, 0.1); width: 97%;\">\n",
    "    <span style=\"font-weight: bold; color: #6a1b9a; animation: pulse 2s infinite;\"></span>COMPX310-2025B Lab 2 <br>Decision Trees Forest Cover Type Prediction\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50763f5",
   "metadata": {},
   "source": [
    "## Lab Information\n",
    "- **Due Date:** Monday, September 29, 11:59 PM\n",
    "- **Weight:** 3% of your total COMPX310 grade\n",
    "- **Platform:** VSCode, Kaggle or Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b71d4e",
   "metadata": {},
   "source": [
    "## 1. Introduction to This Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a78ae",
   "metadata": {},
   "source": [
    "### What is a Decision Tree?\n",
    "A **decision tree** is a machine learning algorithm that makes predictions by asking a series of yes/no questions about the data. Think of it like a flowchart:\n",
    "- Each node (box) asks a question about a feature\n",
    "- Each branch represents a possible answer\n",
    "- The leaves (final boxes) give us the prediction\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:2000/1*S10T4ah3_JqdQ-eY6Hau0Q.png\" width=\"600\" height=\"400\">\n",
    "</div>\n",
    "\n",
    "### What Will You Learn?\n",
    "In this lab, you will:\n",
    "1. Load and explore a real-world dataset\n",
    "2. Build decision tree models with different settings\n",
    "3. Use validation techniques to find the best model\n",
    "4. Visualize your results with plots\n",
    "5. Compare different approaches to model evaluation\n",
    "\n",
    "### The Dataset: Forest Cover Type\n",
    "We will predict what type of forest covers a specific area based on geographical and environmental features like elevation, slope, and distance to water sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284ad03",
   "metadata": {},
   "source": [
    "## 2. Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65941e",
   "metadata": {},
   "source": [
    "### Background\n",
    "This dataset comes from the US Forest Service and contains information about forest areas in northern Colorado. Each data point represents a 30×30 meter area of forest. The goal is to predict which of 7 different tree types grows in each area.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://assets.weforum.org/article/image/responsive_big_webp_qGgfxhM2PU3tyvAFoc-5FDTxmVY5sDcL8JSIo5Kj4aI.webp\" width=\"600\" height=\"400\">\n",
    "</div>\n",
    "The study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "### Study Areas Background\n",
    "- **Neota (Area 2)**: Probably has the highest mean elevational value of the 4 wilderness areas\n",
    "- **Rawah (Area 1)** and **Comanche Peak (Area 3)**: Would have a lower mean elevational value\n",
    "- **Cache la Poudre (Area 4)**: Would have the lowest mean elevational value\n",
    "\n",
    "### Primary Tree Species by Area\n",
    "- **Neota**: Mainly spruce/fir (type 1)\n",
    "- **Rawah and Comanche Peak**: Mainly lodgepole pine (type 2), followed by spruce/fir and aspen (type 5)\n",
    "- **Cache la Poudre**: Mainly Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4)\n",
    "\n",
    "The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values. Cache la Poudre would probably be more unique than the others, due to its relatively low elevation range and species composition.\n",
    "\n",
    "### Dataset Features\n",
    "The dataset contains 54 features total. Here's what each feature means:\n",
    "\n",
    "| Feature Name | Data Type | Unit | Description |\n",
    "|--------------|-----------|------|-------------|\n",
    "| Elevation | Numerical | meters | Elevation in meters |\n",
    "| Aspect | Numerical | degrees azimuth | Aspect in degrees azimuth |\n",
    "| Slope | Numerical | degrees | Slope in degrees |\n",
    "| Horizontal_Distance_To_Hydrology | Numerical | meters | Horizontal distance to nearest surface water features |\n",
    "| Vertical_Distance_To_Hydrology | Numerical | meters | Vertical distance to nearest surface water features |\n",
    "| Horizontal_Distance_To_Roadways | Numerical | meters | Horizontal distance to nearest roadway |\n",
    "| Hillshade_9am | Numerical | 0-255 index | Hillshade index at 9am, summer solstice |\n",
    "| Hillshade_Noon | Numerical | 0-255 index | Hillshade index at noon, summer solstice |\n",
    "| Hillshade_3pm | Numerical | 0-255 index | Hillshade index at 3pm, summer solstice |\n",
    "| Horizontal_Distance_To_Fire_Points | Numerical | meters | Horizontal distance to nearest wildfire ignition points |\n",
    "| Wilderness_Area (4 binary columns) | Binary | 0 or 1 | Wilderness area designation (0 = absence, 1 = presence) |\n",
    "| Soil_Type (40 binary columns) | Binary | 0 or 1 | Soil Type designation (0 = absence, 1 = presence) |\n",
    "| class | Integer | 1-7 | **TARGET VARIABLE**: Forest Cover Type designation |\n",
    "\n",
    "### Forest Cover Types (Target Classes)\n",
    "The **class** is what we want to predict. There are 7 different types:\n",
    "1. **Spruce/Fir**\n",
    "2. **Lodgepole Pine** \n",
    "3. **Ponderosa Pine**\n",
    "4. **Cottonwood/Willow**\n",
    "5. **Aspen**\n",
    "6. **Douglas-fir**\n",
    "7. **Krummholz**\n",
    "\n",
    "### Additional Information\n",
    "- **Total Features:** 54 (10 numerical + 4 wilderness areas + 40 soil types)\n",
    "- **Target:** 1 (class)\n",
    "- **Data Format:** Raw form (not scaled) with binary columns for qualitative variables\n",
    "- **Learn more:** https://archive.ics.uci.edu/dataset/31/covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68743a",
   "metadata": {},
   "source": [
    "## 3. Required Files\n",
    "You need to download these two CSV files:\n",
    "- `covtype_train.csv` - for training your models\n",
    "- `covtype_test.csv` - for final testing\n",
    "\n",
    "**Important:** Make sure to keep both files in the same folder you open in VSCode or upload both files to your Kaggle or Google Colab environment before starting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395fe90",
   "metadata": {},
   "source": [
    "## 4. Assignment Tasks\n",
    "### **Complete the missing parts marked with # TODO comments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4278c",
   "metadata": {},
   "source": [
    "### Task 1: Data Loading and Preparation (Setup)\n",
    "\n",
    "**What you need to do:**\n",
    "1. Import all necessary libraries (pandas, numpy, sklearn, matplotlib, seaborn)\n",
    "2. Set your random seed using the last 4 digits of your student ID (or sum of IDs if working in pairs)\n",
    "3. Load both CSV files (`covtype_train.csv` and `covtype_test.csv`)\n",
    "4. Separate features (X) and target variable (y) from both datasets\n",
    "   - **X**: All columns except \"class\" which is Cover_Type\n",
    "   - **y**: Only the \"class\" column\n",
    "5. Display basic information about your datasets (shape, first few rows)\n",
    "\n",
    "**Important Note:** For all random steps in this lab, always use last four digits of your student ID as the random seed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Data Loading and Preparation\n",
    "# Complete the missing parts marked with # COMPLETE comments\n",
    "\n",
    "# Step 1: Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# COMPLETE: Import graphviz for tree visualization\n",
    "# import graphviz\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "\n",
    "# Step 2: Set your random seed\n",
    "# COMPLETE: Replace XXXX with the last 4 digits of your student ID\n",
    "ID = XXXX  # COMPLETE: Change this to your student ID\n",
    "\n",
    "np.random.seed(ID)\n",
    "print(f\"✓ Random seed set to: {ID}\")\n",
    "\n",
    "# Step 3: Load the datasets\n",
    "# COMPLETE: Load the CSV files using pd.read_csv()\n",
    "train_df = # COMPLETE: Load 'covtype_train.csv'\n",
    "test_df = # COMPLETE: Load 'covtype_test.csv'\n",
    "\n",
    "# Clean up column names by removing leading/trailing spaces\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "test_df.columns = test_df.columns.str.strip()\n",
    "\n",
    "print(\"✓ Data loaded successfully!\")\n",
    "\n",
    "# Step 4: Check your data\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# COMPLETE: Display first 5 rows of training data\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "# COMPLETE: Use .head() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fd4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Separate features (X) and target (y)\n",
    "# COMPLETE: Create X by dropping 'class' column, y by selecting 'class'\n",
    "y_train_full = # COMPLETE: Select 'class' from train_df\n",
    "X_train_full = # COMPLETE: Drop 'class' from train_df\n",
    "\n",
    "y_test = # COMPLETE: Select 'class' from test_df\n",
    "X_test = # COMPLETE: Drop 'class' from test_df  \n",
    "\n",
    "# Verify the separation\n",
    "print(f\"\\nFeatures shape: {X_train_full.shape} (should be 54 columns)\")\n",
    "print(f\"Target values: {sorted(y_train_full.unique())} (should be 1-7)\")\n",
    "\n",
    "print(\"\\n✓ Task 1 completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ff9fa",
   "metadata": {},
   "source": [
    "### Task 2: Basic Data Analysis (Understand Your Data)\n",
    "**What you need to do:**\n",
    "1. **Dataset Information**: Check data types, missing values, and basic statistics\n",
    "2. **Target Distribution**: Create a bar plot showing how many examples of each class you have\n",
    "3. **Feature Distributions**: Create histograms for the first 10 numerical features\n",
    "4. **Correlation Analysis**: Create a correlation heatmap for numerical features\n",
    "5. **Feature vs Target**: Create box plots showing how key features (like Elevation) vary by class\n",
    "\n",
    "**Why this is important:**\n",
    "- **Histograms** help you see if features are normally distributed, skewed, or have outliers\n",
    "- **Correlation heatmaps** show which features are related to each other\n",
    "- **Box plots** help you understand which features might be most useful for prediction\n",
    "- Understanding your data helps you make better modeling decisions\n",
    "\n",
    "**Add markdown cells to explain what you observe in each plot!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0011e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Data Exploration - Understanding Your Data\n",
    "# Complete the missing parts marked with # COMPLETE comments\n",
    "\n",
    "print(\"TASK 2: DATA EXPLORATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Part 1: Basic Dataset Information\n",
    "print(\"1. BASIC DATASET INFORMATION\")\n",
    "\n",
    "# COMPLETE: Use .info() to check data types and missing values\n",
    "train_df.info()\n",
    "\n",
    "# COMPLETE: Count missing values in both datasets\n",
    "missing_train = # COMPLETE: Use train_df.isnull().sum().sum()\n",
    "missing_test = # COMPLETE: Use test_df.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nMissing values - Training: {missing_train}, Test: {missing_test}\")\n",
    "\n",
    "# COMPLETE: Get summary statistics for first 10 numerical features\n",
    "print(\"\\nSummary statistics for first 10 features:\")\n",
    "# COMPLETE: Use train_df.iloc[:, :10].describe()\n",
    "\n",
    "# Part 2: Target Distribution\n",
    "print(\"\\n2. TARGET DISTRIBUTION\")\n",
    "\n",
    "# COMPLETE: Count how many examples of each class (class)  we have\n",
    "cover_counts = # COMPLETE: Use train_df['class'].value_counts().sort_index()\n",
    "\n",
    "print(\"Cover Type distribution:\")\n",
    "print(cover_counts)\n",
    "\n",
    "# COMPLETE: Create bar plot of target distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "# COMPLETE: Use cover_counts.plot(kind='bar')\n",
    "\n",
    "plt.title('Forest Cover Types Distribution')\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Number of Examples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Part 3: Feature Distributions\n",
    "print(\"\\n3. FEATURE DISTRIBUTIONS\")\n",
    "\n",
    "# First 10 numerical features\n",
    "numerical_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', \n",
    "                     'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "                     'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n",
    "                     'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "# COMPLETE: Create histograms for all numerical features\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    # COMPLETE: Create histogram - axes[i].hist(train_df[feature], bins=30, alpha=0.7)\n",
    "    \n",
    "    axes[i].set_title(f'{feature}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Part 4: Correlation Analysis\n",
    "print(\"\\n4. CORRELATION ANALYSIS\")\n",
    "\n",
    "# COMPLETE: Calculate correlation matrix for numerical features\n",
    "correlation_matrix = # COMPLETE: Use train_df[numerical_features].corr()\n",
    "\n",
    "# COMPLETE: Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "# COMPLETE: Use sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Part 5: Feature vs Target Analysis\n",
    "print(\"\\n5. FEATURE vs TARGET ANALYSIS\")\n",
    "\n",
    "# COMPLETE: Create box plot showing Elevation by class \n",
    "plt.figure(figsize=(12, 8))\n",
    "# COMPLETE: Use sns.boxplot(data=train_df, x='class', y='Elevation')\n",
    "\n",
    "plt.title('Elevation by Cover Type')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# COMPLETE: Analyze wilderness areas by cover type\n",
    "wilderness_cols = ['Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Wilderness_Area_4']\n",
    "# COMPLETE: Use train_df.groupby('class')[wilderness_cols].sum()\n",
    "wilderness_summary = \n",
    "\n",
    "print(\"Wilderness Area by Cover Type:\")\n",
    "print(wilderness_summary)\n",
    "\n",
    "print(\"\\n✓ Task 2 completed! Add markdown cells to explain your observations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88e8d3",
   "metadata": {},
   "source": [
    "### Task 3: Cross-Validation Experiment - Build and Validate Decision Trees (1 mark)\n",
    "\n",
    "**What you need to do:**\n",
    "\n",
    "**Step 1: Set up the experiment**\n",
    "- Split your training data into 80% for model fitting and 20% for validation\n",
    "- Repeat this process **30 times** with different random splits\n",
    "- Use `random_state=ID+i` where `i` goes from 0 to 29\n",
    "\n",
    "**Step 2: Test different tree complexities**\n",
    "For each of the 30 splits, build 15 different decision trees using these `max_leaf_nodes` values:\n",
    "```\n",
    "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]\n",
    "```\n",
    "\n",
    "**Step 3: Collect results**\n",
    "- For each tree, measure its accuracy on the validation set\n",
    "- You should collect **450 accuracy values** total (30 splits × 15 parameter values)\n",
    "\n",
    "**What is max_leaf_nodes?**\n",
    "- This parameter controls how complex your decision tree can be\n",
    "- **Small values** (like 2, 4): Simple tree, might be too simple (underfitting)\n",
    "- **Large values** (like 16384): Complex tree, might memorize training data (overfitting)\n",
    "- We test different values to find the best balance\n",
    "\n",
    "**What is Cross-Validation?**\n",
    "- We split our training data to test how well our model works on \"unseen\" data\n",
    "- This helps us choose the best parameters without using our test set\n",
    "- Using 30 different splits gives us a better estimate of performance\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*GhKMAUmi4bfFiEwZCPlDsA.png\" width=\"700\" height=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Cross-Validation Experiment - Build and Validate Decision Trees\n",
    "# Complete the missing parts marked with # COMPLETE comments\n",
    "\n",
    "print(\"TASK 3: CROSS-VALIDATION EXPERIMENT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# COMPLETE: Step 1: Set up experiment parameters\n",
    "max_leaf_nodes_values = [ ]\n",
    "\n",
    "print(f\"Testing {len(max_leaf_nodes_values)} different max_leaf_nodes values\")\n",
    "print(f\"Will perform 30 splits × 15 parameters = {30 * 15} total experiments\")\n",
    "\n",
    "# Initialize storage for results\n",
    "all_accuracies = []\n",
    "all_max_leaf_nodes = []\n",
    "all_split_numbers = []\n",
    "\n",
    "# Step 2: Run the cross-validation experiment\n",
    "print(\"\\nStarting experiment...\")\n",
    "\n",
    "# COMPLETE: Create loop for 30 different train/validation splits\n",
    "for i in range(xx):\n",
    "    print(f\"Split {i+1}/30...\", end=\" \")\n",
    "    \n",
    "    # COMPLETE: Split training data into 80% train, 20% validation\n",
    "    # Use train_test_split with test_size=0.2, random_state=ID+i, stratify=y_train_full\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        # COMPLETE: Fill in parameters\n",
    "    )\n",
    "    \n",
    "    # COMPLETE: Test each max_leaf_nodes value\n",
    "    for max_nodes in max_leaf_nodes_values:\n",
    "        \n",
    "        # COMPLETE: Create DecisionTreeClassifier with max_leaf_nodes=max_nodes, random_state=ID\n",
    "        tree_model = DecisionTreeClassifier(\n",
    "            # COMPLETE: Fill in parameters\n",
    "        )\n",
    "        \n",
    "        # COMPLETE: Train the model\n",
    "        # COMPLETE: Use .fit(X_train, y_train)\n",
    "        \n",
    "        # COMPLETE: Make predictions on validation set\n",
    "        y_val_pred = # COMPLETE: Use .predict(X_val)\n",
    "        \n",
    "        # COMPLETE: Calculate accuracy\n",
    "        accuracy = accuracy_score(# COMPLETE: y_val, y_val_pred)\n",
    "        \n",
    "        # Store results\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_max_leaf_nodes.append(max_nodes)\n",
    "        all_split_numbers.append(i + 1)\n",
    "    \n",
    "    print(\"✓\")\n",
    "\n",
    "print(f\"\\n✓ Experiment completed! Total results: {len(all_accuracies)}\")\n",
    "\n",
    "# Step 3: Organize results\n",
    "# COMPLETE: Create DataFrame with results\n",
    "results_df = pd.DataFrame({\n",
    "    # COMPLETE: Fill in the three columns\n",
    "    'split_number': ,\n",
    "    'max_leaf_nodes': ,\n",
    "    'validation_accuracy': \n",
    "})\n",
    "\n",
    "print(\"First 10 results:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Step 4: Analyze results\n",
    "print(\"\\nValidation accuracy summary:\")\n",
    "# COMPLETE: Show summary statistics using .describe()\n",
    "\n",
    "# COMPLETE: Calculate mean accuracy for each max_leaf_nodes\n",
    "summary_stats = results_df.groupby('max_leaf_nodes')['validation_accuracy'].agg([\n",
    "    # COMPLETE: Add 'mean', 'std' aggregation functions\n",
    "]).round(4)\n",
    "\n",
    "print(\"\\nMean performance by max_leaf_nodes:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# COMPLETE: Find best performing max_leaf_nodes\n",
    "best_max_leaf_nodes = # COMPLETE: Use summary_stats['mean'].idxmax()\n",
    "\n",
    "print(f\"\\nBest max_leaf_nodes based on validation: {best_max_leaf_nodes}\")\n",
    "print(f\"Mean accuracy: {summary_stats.loc[best_max_leaf_nodes, 'mean']:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Task 3 completed! Ready for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8a208",
   "metadata": {},
   "source": [
    "### Task 4: Create Violin Plot (1 mark)\n",
    "\n",
    "**What you need to do:**\n",
    "1. Create a **violin plot** using seaborn that shows the distribution of validation accuracies\n",
    "2. Group results by `max_leaf_nodes` values (x-axis should show all 15 values)\n",
    "3. Y-axis should show validation accuracy\n",
    "4. The plot should clearly show 15 \"violins\" - one for each `max_leaf_nodes` value\n",
    "\n",
    "**What is a Violin Plot?**\n",
    "- Similar to a box plot but shows the full shape of the data distribution\n",
    "- **Width** indicates how common different accuracy values are\n",
    "- **Wider parts** = more common accuracy values\n",
    "- **Narrower parts** = less common accuracy values\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/0*PHYwIcm5knwcrTek.png\" width=\"600\" height=\"500\">\n",
    "</div>\n",
    "\n",
    "**Add a markdown cell explaining:**\n",
    "- Which `max_leaf_nodes` value appears to perform best based on the violin plot?\n",
    "- What patterns do you observe as `max_leaf_nodes` increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Create Violin Plot - Visualizing Validation Results\n",
    "# Complete the missing parts marked with # COMPLETE comments\n",
    "\n",
    "print(\"TASK 4: VIOLIN PLOT VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Step 1: Check our data from Task 3\n",
    "print(f\"We have {len(results_df)} validation results\")\n",
    "print(f\"Testing {len(results_df['max_leaf_nodes'].unique())} different max_leaf_nodes values\")\n",
    "\n",
    "# Step 2: Create the violin plot\n",
    "print(\"\\nCreating violin plot...\")\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# COMPLETE: Create violin plot using sns.violinplot()\n",
    "# Parameters needed: data=results_df, x='max_leaf_nodes', y='validation_accuracy'\n",
    "sns.violinplot(\n",
    "    # COMPLETE: Fill in the parameters\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Validation Accuracy Distribution for Different max_leaf_nodes Values')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "\n",
    "# COMPLETE: Rotate x-axis labels for better readability\n",
    "# Use plt.xticks(rotation=45)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Find the best performing parameter\n",
    "print(\"\\nAnalyzing results...\")\n",
    "\n",
    "# COMPLETE: Calculate mean accuracy for each max_leaf_nodes value\n",
    "# Use results_df.groupby('max_leaf_nodes')['validation_accuracy'].mean()\n",
    "mean_accuracies = \n",
    "\n",
    "# COMPLETE: Find the max_leaf_nodes with highest mean accuracy\n",
    "# Use mean_accuracies.idxmax()\n",
    "best_max_leaf_nodes = \n",
    "\n",
    "print(f\"Best max_leaf_nodes based on validation: {best_max_leaf_nodes}\")\n",
    "print(f\"Mean validation accuracy: {mean_accuracies[best_max_leaf_nodes]:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Task 4 completed!\")\n",
    "print(\"Now write a markdown cell explaining your observations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64a47f",
   "metadata": {},
   "source": [
    "### Task 5: Test Set Evaluation - Final Model Comparison (1 mark)\n",
    "\n",
    "**What you need to do:**\n",
    "\n",
    "**Step 1: Train on full training data**\n",
    "- Use the complete training dataset (not split)\n",
    "- Train 15 decision trees, one for each `max_leaf_nodes` value\n",
    "- Test each tree on the test set and record the accuracy\n",
    "\n",
    "**Step 2: Create line plot**\n",
    "- Plot test accuracy (y-axis) vs `max_leaf_nodes` (x-axis)\n",
    "- Use a line plot with markers to show the results\n",
    "- Clearly mark the best-performing parameter value\n",
    "\n",
    "**Step 3: Compare results**\n",
    "Answer these questions in markdown cells:\n",
    "- **Agreement**: Is the `max_leaf_nodes` value with the highest test accuracy the same as the one with the \"highest violin\" in your validation plot?\n",
    "- **Analysis**: Do the validation and test results agree on the best parameter? Why or why not?\n",
    "\n",
    "**Step 4: Visualize decision tree**\n",
    "- Train a decision tree with `max_leaf_nodes=8` on the full training data\n",
    "- Plot this decision tree using `sklearn.tree.export_graphviz` and `graphviz`\n",
    "- Add a markdown cell explaining what you observe in the tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403eb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Test Set Evaluation - Final Model Comparison\n",
    "# Complete the missing parts marked with # COMPLETE comments\n",
    "\n",
    "print(\"TASK 5: TEST SET EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Step 1: Train models on full training data and test on test set\n",
    "print(\"Training models on full training data...\")\n",
    "\n",
    "test_accuracies = []\n",
    "\n",
    "# COMPLETE: Train 15 decision trees with different max_leaf_nodes values\n",
    "for max_nodes in max_leaf_nodes_values:\n",
    "    print(f\"Testing max_leaf_nodes={max_nodes}...\")\n",
    "    \n",
    "    # COMPLETE: Create DecisionTreeClassifier with max_leaf_nodes=max_nodes, random_state=ID\n",
    "    tree_model = DecisionTreeClassifier(\n",
    "        # COMPLETE: Fill in parameters\n",
    "    )\n",
    "    \n",
    "    # COMPLETE: Train on full training data\n",
    "    # COMPLETE: Use .fit(X_train_full, y_train_full)\n",
    "    \n",
    "    # COMPLETE: Test on test set\n",
    "    y_test_pred = # COMPLETE: Use .predict(X_test)\n",
    "    \n",
    "    # COMPLETE: Calculate test accuracy\n",
    "    accuracy = accuracy_score(# COMPLETE: y_test, y_test_pred)\n",
    "    \n",
    "    test_accuracies.append(accuracy)\n",
    "    print(f\"  Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ All models tested!\")\n",
    "\n",
    "# Step 2: Create line plot of test results\n",
    "print(\"\\nCreating test results plot...\")\n",
    "\n",
    "# COMPLETE: Find best test performance\n",
    "best_test_idx = # COMPLETE: Use np.argmax(test_accuracies)\n",
    "best_test_max_leaf_nodes = max_leaf_nodes_values[best_test_idx]\n",
    "best_test_accuracy = test_accuracies[best_test_idx]\n",
    "\n",
    "print(f\"Best test performance: max_leaf_nodes={best_test_max_leaf_nodes}, accuracy={best_test_accuracy:.4f}\")\n",
    "\n",
    "# COMPLETE: Create line plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "# COMPLETE: Use plt.plot() with max_leaf_nodes_values, test_accuracies, and markers\n",
    "plt.plot(# COMPLETE: x=max_leaf_nodes_values, y=test_accuracies, marker='o', linewidth=2, markersize=8)\n",
    "\n",
    "plt.title('Test Set Accuracy vs max_leaf_nodes')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "# COMPLETE: Use log scale for x-axis since values vary widely\n",
    "plt.xscale('log')\n",
    "\n",
    "# COMPLETE: Mark the best performing point\n",
    "plt.plot(best_test_max_leaf_nodes, best_test_accuracy, 'ro', markersize=12, \n",
    "         label=f'Best: {best_test_max_leaf_nodes} nodes')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Compare validation and test results\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"VALIDATION vs TEST COMPARISON\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# COMPLETE: Get the best max_leaf_nodes from validation (from Task 3)\n",
    "best_validation_max_leaf_nodes = # COMPLETE: From Task 3 results\n",
    "\n",
    "print(f\"Best from validation: max_leaf_nodes = {best_validation_max_leaf_nodes}\")\n",
    "print(f\"Best from test set: max_leaf_nodes = {best_test_max_leaf_nodes}\")\n",
    "\n",
    "# COMPLETE: Check if they agree\n",
    "agreement = best_validation_max_leaf_nodes == best_test_max_leaf_nodes\n",
    "print(f\"Do validation and test agree? {agreement}\")\n",
    "\n",
    "if agreement:\n",
    "    print(\"✓ Great! Validation successfully identified the best parameter.\")\n",
    "else:\n",
    "    print(\"⚠ Validation and test disagree. This suggests overfitting to validation set.\")\n",
    "\n",
    "# Step 4: Visualize decision tree with max_leaf_nodes=8\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"DECISION TREE VISUALIZATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"Training decision tree with max_leaf_nodes=8...\")\n",
    "\n",
    "# COMPLETE: Create and train tree with max_leaf_nodes=8\n",
    "viz_tree = DecisionTreeClassifier(\n",
    "    # COMPLETE: max_leaf_nodes=8, random_state=ID\n",
    ")\n",
    "\n",
    "# COMPLETE: Train on full training data\n",
    "# COMPLETE: Use .fit(X_train_full, y_train_full)\n",
    "\n",
    "# Get accuracy for this specific tree\n",
    "viz_predictions = viz_tree.predict(X_test)\n",
    "viz_accuracy = accuracy_score(y_test, viz_predictions)\n",
    "print(f\"Tree with max_leaf_nodes=8 test accuracy: {viz_accuracy:.4f}\")\n",
    "\n",
    "# COMPLETE: Visualize the tree using graphviz\n",
    "print(\"\\nCreating tree visualization...\")\n",
    "\n",
    "# COMPLETE: Export tree to graphviz format\n",
    "dot_data = tree.export_graphviz(\n",
    "    viz_tree,\n",
    "    feature_names=list(X_train_full.columns),\n",
    "    class_names=[str(i) for i in range(1, 8)],  # Cover types 1-7\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    out_file=None\n",
    ")\n",
    "\n",
    "# COMPLETE: Create graphviz visualization\n",
    "# COMPLETE: graph = graphviz.Source(dot_data, format=\"png\")\n",
    "# COMPLETE: graph\n",
    "\n",
    "print(\"✓ Tree visualization completed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ TASK 5 COMPLETED!\")\n",
    "print(\"\\nNow add markdown cells to discuss:\")\n",
    "print(\"- Do validation and test results agree?\")\n",
    "print(\"- What does the decision tree structure tell you?\")\n",
    "print(\"- Which features appear most important?\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873894d4",
   "metadata": {},
   "source": [
    "### Task 6: Discussion and Analysis - Results Interpretation\n",
    "\n",
    "**Answer these questions in markdown cells:**\n",
    "\n",
    "1. **Model Performance**: \n",
    "   - What was your best validation accuracy and best test accuracy?\n",
    "   - Do these results seem reasonable for a 7-class classification problem?\n",
    "\n",
    "2. **Parameter Selection**:\n",
    "   - Did validation and test results agree on the best `max_leaf_nodes`?\n",
    "   - Which approach (validation or test) should you trust for selecting parameters? Why?\n",
    "\n",
    "3. **Overfitting vs Underfitting**:\n",
    "   - Which `max_leaf_nodes` values likely caused underfitting? Why?\n",
    "   - Which values likely caused overfitting? Why?\n",
    "   - Where do you think the \"sweet spot\" is?\n",
    "\n",
    "4. **Decision Tree Interpretation**:\n",
    "   - Looking at your tree with `max_leaf_nodes=8`, which features seem most important?\n",
    "   - Can you trace through a decision path and understand how the tree makes predictions?\n",
    "\n",
    "5. **Real-world Application**:\n",
    "   - How could this forest cover prediction model be useful in practice?\n",
    "   - What limitations might this approach have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8ad24",
   "metadata": {},
   "source": [
    "## 5. Important Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630048c",
   "metadata": {},
   "source": [
    "### Technical Requirements:\n",
    "- **Random Seeds**: Always use your student ID (last 4 digits) for random_state parameters\n",
    "- **Pair Programming**: If working with a buddy, use the sum of both student IDs\n",
    "- **Code Comments**: Add comments to explain what your code does\n",
    "- **Markdown Explanations**: Use markdown cells to explain your observations and findings\n",
    "\n",
    "### What to Include:\n",
    "- Your name and student ID at the top\n",
    "- All plots should be clearly labeled with titles and axis labels\n",
    "- Markdown explanations for each major step\n",
    "- Discussion of your results and findings\n",
    "- Answers to all analysis questions\n",
    "\n",
    "### Submission:\n",
    "- Execute all code cells so outputs are visible\n",
    "- Print your notebook to HTML\n",
    "- Submit HTML to Canvas before the deadline\n",
    "- **Both partners must submit if working in pairs**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc107e",
   "metadata": {},
   "source": [
    "## 6. Helpful Hints\n",
    "\n",
    "### For Decision Tree Visualization:\n",
    "```python\n",
    "# Hint for plotting trees:\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(tree_model, out_file=None)\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph\n",
    "```\n",
    "\n",
    "### For Advanced Visualization (Optional):\n",
    "```python\n",
    "# If you want to try a fancier tree visualization:\n",
    "!pip install dtreeviz\n",
    "import dtreeviz\n",
    "# Note: You'll need to adjust class labels for dtreeviz (subtract 1 from class)\n",
    "```\n",
    "\n",
    "## Installing Graphviz for Tree Visualization\n",
    "\n",
    "- Download Graphviz from https://graphviz.org/download/ (choose Windows or other installer)\n",
    "- During installation, **check the option \"Add Graphviz to system PATH\"** if available\n",
    "- If PATH option wasn't available, manually add `C:\\Program Files\\Graphviz\\bin` to your system PATH\n",
    "- **Restart VS Code completely** after installation\n",
    "- Test by running `dot -V` in command prompt to verify installation\n",
    "\n",
    "### Remember:\n",
    "- Learning is easier with a buddy - pair programming is encouraged!\n",
    "- Don't share your work outside your pair\n",
    "- Ask questions if you get stuck\n",
    "- Focus on understanding the concepts, not just getting the code to work\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db335630",
   "metadata": {},
   "source": [
    "## 12. Learning Objectives Check\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "- [ ] Load and explore a real dataset\n",
    "- [ ] Understand what decision trees are and how they work\n",
    "- [ ] Use cross-validation to select model parameters\n",
    "- [ ] Create and interpret violin plots\n",
    "- [ ] Compare validation and test set performance\n",
    "- [ ] Visualize and interpret decision trees\n",
    "- [ ] Discuss overfitting, underfitting, and model complexity\n",
    "\n",
    "**Good luck with your assignment!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
