{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Arial', sans-serif; font-size: 3rem; color: #6a1b9a; text-align: center; margin: 0; \n",
    "           text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1); background-color: #f5f5f5; padding: 10px; \n",
    "           border-radius: 10px; border: 4px solid #6a5acd; box-shadow: 2px 2px 12px rgba(0, 0, 0, 0.1); width: 97%;\">\n",
    "    <span style=\"font-weight: bold; color: #6a1b9a; animation: pulse 2s infinite;\"></span>COMPX310-2025 Lab 7 <br> Support Vector Machines\n",
    "<br>Banking Marketing Campaign Analysis</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://www.driveresearch.com/wp-content/uploads/2024/10/bank-marketing-strategies.jpg\" width=\"800\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Overview\n",
    "**Total Points: 3**\n",
    "\n",
    "In this lab, you will apply **Support Vector Machines (SVM)** for classification and **Support Vector Regression (SVR)** to analyze banking data.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand and apply Support Vector Machines for classification\n",
    "- Implement Support Vector Regression for numerical prediction\n",
    "- Evaluate model performance using appropriate metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://ts2.tc.mm.bing.net/th/id/OIP-C.JFff7dHIUtNoMov7paoXRQHaEq?rs=1&pid=ImgDetMain&o=7&rm=3\" width=\"800\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### Background\n",
    "StirBank has been running marketing campaigns to encourage customers to set up regular savings deposits. However, calling many customers is costly and risks annoying people. The bank needs a data-driven approach to identify which customers are most likely to respond positively.\n",
    "\n",
    "### Problem Statement\n",
    "**Part 1 - Classification Task:** Predict whether a customer will make a deposit (`made_deposit`) based on their characteristics and previous interactions.\n",
    "\n",
    "**Part 2 - Regression Task:** Predict a customer's current balance based on their demographic and banking characteristics.\n",
    "\n",
    "### Why Data Mining?\n",
    "Data mining is suitable because:\n",
    "- We have historical data with known outcomes\n",
    "- The relationships between variables are complex and non-linear\n",
    "- Manual rules would be difficult to create and maintain\n",
    "- Automated prediction can save costs and improve targeting\n",
    "\n",
    "### Key Terminology\n",
    "- **Model**: A mathematical representation learned from data\n",
    "- **Features/Variables**: Input attributes used for prediction\n",
    "- **Target**: The variable we want to predict\n",
    "- **SVM**: Support Vector Machine - finds optimal decision boundaries\n",
    "- **Kernel**: Function that transforms data into higher dimensions\n",
    "- **Hyperparameters**: Parameters that control the learning process (C, gamma, kernel type)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all necessary Python libraries for this lab. You will need:\n",
    "- Data manipulation libraries (pandas, numpy)\n",
    "- Visualization libraries (matplotlib, seaborn)\n",
    "- Preprocessing tools from scikit-learn (StandardScaler, LabelEncoder, train_test_split)\n",
    "- SVM models from scikit-learn (SVC for classification, SVR for regression)\n",
    "- Model selection tools (GridSearchCV for hyperparameter tuning)\n",
    "- Evaluation metrics for both classification and regression tasks\n",
    "- Configure any necessary settings (warnings, plot styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Understanding \n",
    "\n",
    "### Load and Explore the Dataset\n",
    "\n",
    "Load the 'bank-tr.csv' file and perform initial exploration:\n",
    "- Read the CSV file into a pandas DataFrame\n",
    "- Display the shape of the dataset (should be 8000 rows × 20 columns)\n",
    "- Show the first few rows to understand the data structure\n",
    "- Display information about column data types and any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Review the variables in the dataset and fill type and Usefulness.\n",
    "- Go through each column and classify it as **categorical** or **numerical**\n",
    "- Mark it as **nominal, ordinal, continuous, or discrete**\n",
    "- Decide whether it is useful for prediction or should be dropped\n",
    "\n",
    "| Variable | Description | Type | Usefulness |\n",
    "|----------|-------------|------|------------|\n",
    "| accountID | Unique customer identifier |  |  |\n",
    "| town | Customer's town |  |  |\n",
    "| country | Customer's country |  |  |\n",
    "| age | Customer's age |  |  |\n",
    "| job | Type of job |  |  |\n",
    "| marital | Marital status |  |  |\n",
    "| education | Education level |  |  |\n",
    "| defaulted? | Has credit in default |  |  |\n",
    "| current_balance | Current account balance |  |  |\n",
    "| housing | Has housing loan |  |  |\n",
    "| has_loan | Has personal loan |  |  |\n",
    "| last_contact | Contact communication type |  |  |\n",
    "| cc_tr | Number of contacts in campaign |  |  |\n",
    "| last_contact_day | Day of last contact |  |  |\n",
    "| last_contact_month | Month of last contact |  |  |\n",
    "| campaign | Number of contacts in this campaign |  |  |\n",
    "| days_since_last_contact | Days since previous campaign |  |  |\n",
    "| previous | Number of previous contacts |  |  |\n",
    "| poutcome | Outcome of previous campaign |  |  |\n",
    "| made_deposit | Did customer make deposit? (**TARGET VARIABLE**) |  |  |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Generate and display summary statistics:\n",
    "- Use appropriate pandas methods to display summary statistics for numerical variables\n",
    "- For categorical variables, display the unique values and their frequencies\n",
    "- Check for any missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Analysis\n",
    "\n",
    "Analyze the distribution of the target variable 'made_deposit':\n",
    "- Display value counts and percentages\n",
    "- Create visualizations to show the distribution (bar chart and/or pie chart)\n",
    "- Assess whether the classes are balanced or imbalanced\n",
    "- Comment on what you observe about the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Preparation \n",
    "\n",
    "### Step 4.1: Data Quality Assessment\n",
    "\n",
    "Examine the data for quality issues:\n",
    "- Check for any inconsistent values in categorical columns (e.g., different spellings or abbreviations)\n",
    "- Look specifically at binary columns like 'housing', 'has_loan', and 'defaulted?' for any unexpected values\n",
    "- Identify any typos or data entry errors that need correction\n",
    "- Document any issues you find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Data Cleaning\n",
    "\n",
    "Clean any data quality issues you identified:\n",
    "- Create a copy of the dataframe for processing\n",
    "- Fix any inconsistent values (e.g., standardize abbreviations)\n",
    "- Document what changes you made and why\n",
    "- Verify that the cleaning was successful by checking the unique values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Visualize Distributions (Before Preprocessing)\n",
    "\n",
    "Create histograms to visualize the distribution of key numerical variables:\n",
    "- Select important numerical features (age, current_balance, campaign, days_since_last_contact, previous)\n",
    "- Create histogram plots to understand their distributions\n",
    "- Look for skewness, outliers, or unusual patterns\n",
    "- These visualizations will help you understand if any transformations are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Remove Irrelevant Features\n",
    "\n",
    "Remove features that won't contribute to prediction:\n",
    "- Drop the 'accountID' column (it's just an identifier with no predictive value)\n",
    "- Drop the 'country' column (all values are the same - UK, so it provides no information)\n",
    "- Consider whether to keep or drop 'town' (too many unique values may not be useful)\n",
    "- Print the remaining columns to verify the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.5: Feature Engineering (Optional)\n",
    "\n",
    "Create new features that might improve model performance:\n",
    "- Consider creating a binary feature indicating whether the customer was contacted before\n",
    "- Consider creating age groups from the continuous age variable\n",
    "- Think about other features that might be useful based on domain knowledge\n",
    "- Document any new features you create and your reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Modeling - Part 1: SVM Classification\n",
    "\n",
    "### Objective\n",
    "Build a Support Vector Machine classifier to predict whether a customer will make a deposit.\n",
    "\n",
    "### Step 5.1: Prepare Data for Classification\n",
    "\n",
    "Separate features and target variable:\n",
    "- Create X (features) by dropping the target column 'made_deposit' and any variables you won't use\n",
    "- Create y (target) from the 'made_deposit' column\n",
    "- Convert the target to binary format (1 for 'yes', 0 for 'no')\n",
    "- Verify the shapes and distribution of your features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2: Encode Categorical Variables\n",
    "\n",
    "Convert categorical variables to numerical format:\n",
    "- Identify which columns are categorical and which are numerical\n",
    "- Use LabelEncoder to encode categorical variables into numerical values\n",
    "- Store the encoders in a dictionary in case you need them later\n",
    "- Verify that all columns are now numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.3: Split Data into Train, Validation, and Test Sets\n",
    "\n",
    "Create three datasets for proper model evaluation:\n",
    "- Split the data into 60% training, 20% validation, and 20% test\n",
    "- First split 80-20 for (train+validation) and test\n",
    "- Then split the 80% into 75-25 to get 60% train and 20% validation\n",
    "- Use stratification to maintain class balance across splits\n",
    "- Set random_state=42 for reproducibility\n",
    "- Print the sizes of each set to verify the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.4: Feature Scaling\n",
    "\n",
    "**⚠️ CRITICAL:** SVMs are very sensitive to feature scales. You must standardize features.\n",
    "\n",
    "Apply StandardScaler to normalize features:\n",
    "- Initialize a StandardScaler\n",
    "- Fit the scaler on the training data ONLY\n",
    "- Transform all three sets (train, validation, test) using the fitted scaler\n",
    "- Never fit the scaler on validation or test data to avoid data leakage\n",
    "- Verify that the scaled features have mean≈0 and std≈1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.5: Build Baseline SVM Model\n",
    "\n",
    "Create a simple baseline SVM model:\n",
    "- Initialize an SVC (Support Vector Classifier) with default parameters\n",
    "- Use the RBF kernel (this is the default)\n",
    "- Train the model on the scaled training data\n",
    "- Make predictions on the validation set\n",
    "- Calculate and display the accuracy score\n",
    "- Print a classification report showing precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.6: Hyperparameter Tuning\n",
    "\n",
    "Use GridSearchCV to find the best hyperparameters:\n",
    "- Define a parameter grid with different values for:\n",
    "  - **C**: Regularization parameter (try 0.1, 1, 10, 100)\n",
    "  - **gamma**: Kernel coefficient (try 'scale', 'auto', 0.001, 0.01, 0.1)\n",
    "  - **kernel**: Kernel type (try 'rbf' and 'linear')\n",
    "- Create a GridSearchCV object with 5-fold cross-validation\n",
    "- Fit the grid search on the training data\n",
    "- Display the best parameters found\n",
    "- Display the best cross-validation score\n",
    "- This process may take several minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.7: Analyze Grid Search Results\n",
    "\n",
    "Examine the grid search results:\n",
    "- Extract the cv_results_ from the grid search\n",
    "- Create a DataFrame to view the results in a structured format\n",
    "- Display the top 10 parameter combinations\n",
    "- Note which parameters seem to work best\n",
    "- Compare different kernels and their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.8: Train Final SVM Model\n",
    "\n",
    "Use the best model from grid search:\n",
    "- Extract the best estimator from the grid search results\n",
    "- Make predictions on the validation set\n",
    "- Calculate accuracy and compare it to the baseline model\n",
    "- Print a detailed classification report\n",
    "- Note the improvement (if any) over the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.9: Final Evaluation on Test Set\n",
    "\n",
    "Evaluate the final model on unseen test data:\n",
    "- Use the best model to make predictions on the test set\n",
    "- Calculate and display the test accuracy\n",
    "- Generate a comprehensive classification report\n",
    "- This is your final model performance - report these numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluation - Classification \n",
    "\n",
    "### Step 6.1: Confusion Matrix\n",
    "\n",
    "Create and visualize a confusion matrix:\n",
    "- Generate a confusion matrix comparing actual vs predicted values\n",
    "- Visualize it using a heatmap with proper labels\n",
    "- Extract the four values: True Negatives, False Positives, False Negatives, True Positives\n",
    "- Interpret what each quadrant means:\n",
    "  - True Negatives: Correctly predicted \"No deposit\"\n",
    "  - False Positives: Predicted \"Deposit\" but actually \"No\" (Type I error)\n",
    "  - False Negatives: Predicted \"No\" but actually \"Deposit\" (Type II error)\n",
    "  - True Positives: Correctly predicted \"Deposit\"\n",
    "- Discuss the business implications of each type of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2: ROC Curve and AUC Score\n",
    "\n",
    "Generate and plot the ROC (Receiver Operating Characteristic) curve:\n",
    "- Train a new SVM with probability=True to get probability predictions\n",
    "- Use the same best parameters from grid search\n",
    "- Get probability predictions for the positive class on the test set\n",
    "- Calculate the false positive rate, true positive rate, and thresholds\n",
    "- Calculate the AUC (Area Under Curve) score\n",
    "- Plot the ROC curve with a diagonal reference line\n",
    "- Interpret the AUC score:\n",
    "  - 0.9-1.0: Excellent\n",
    "  - 0.8-0.9: Good\n",
    "  - 0.7-0.8: Fair\n",
    "  - Below 0.7: Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3: Error Analysis by Segments\n",
    "\n",
    "Analyze where the model performs well and where it struggles:\n",
    "- Create a dataframe combining test features, actual values, and predictions\n",
    "- Add a column indicating whether the prediction was correct\n",
    "- Calculate accuracy for different customer segments (e.g., by job type, age group, marital status)\n",
    "- Identify segments where the model performs poorly\n",
    "- Discuss potential reasons for lower performance in certain segments\n",
    "- Suggest improvements based on this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Modeling - Part 2: Support Vector Regression\n",
    "\n",
    "### Objective\n",
    "Build a Support Vector Regression model to predict a customer's current_balance.\n",
    "\n",
    "### Step 7.1: Prepare Data for Regression\n",
    "\n",
    "Set up the regression task:\n",
    "- Create X (features) by dropping 'current_balance' (target), 'made_deposit' (classification target), and any engineered features you won't use\n",
    "- Create y (target) as the 'current_balance' column\n",
    "- Display summary statistics of the target variable\n",
    "- Create visualizations (histogram and boxplot) to understand the distribution of current_balance\n",
    "- Note any skewness or outliers in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.2: Encode Categorical Variables\n",
    "\n",
    "Encode categorical features for regression:\n",
    "- Identify categorical and numerical columns\n",
    "- Apply LabelEncoder to each categorical column\n",
    "- Store encoders for potential future use\n",
    "- Verify all columns are now numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.3: Split Data for Regression\n",
    "\n",
    "Create train, validation, and test sets:\n",
    "- Use the same 60-20-20 split strategy as in classification\n",
    "- First split: 80% (train+val) and 20% test\n",
    "- Second split: 75% train and 25% validation from the 80%\n",
    "- Use random_state=42 for reproducibility\n",
    "- Print the sizes of each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.4: Feature Scaling for Regression\n",
    "\n",
    "Scale both features and target variable:\n",
    "- Initialize two StandardScalers: one for features (X) and one for target (y)\n",
    "- Fit the feature scaler on training features and transform all three sets\n",
    "- Fit the target scaler on training target and transform all three target sets\n",
    "- Note: Scaling the target helps SVR performance, but remember to inverse transform predictions\n",
    "- Verify the scaling was applied correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.5: Build Baseline SVR Model\n",
    "\n",
    "Create a baseline Support Vector Regression model:\n",
    "- Initialize an SVR with default parameters and RBF kernel\n",
    "- Train on the scaled training data\n",
    "- Make predictions on the validation set (remember these are scaled)\n",
    "- Inverse transform the predictions to get them back to original scale\n",
    "- Calculate and display:\n",
    "  - RMSE (Root Mean Squared Error)\n",
    "  - MAE (Mean Absolute Error)\n",
    "  - R² Score (coefficient of determination)\n",
    "- Interpret these metrics in the context of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.6: Hyperparameter Tuning for SVR\n",
    "\n",
    "Find optimal hyperparameters using GridSearchCV:\n",
    "- Define a parameter grid with:\n",
    "  - **C**: Regularization (try 0.1, 1, 10, 100)\n",
    "  - **gamma**: Kernel coefficient (try 'scale', 'auto', 0.001, 0.01)\n",
    "  - **epsilon**: Epsilon-tube (try 0.01, 0.1, 0.2)\n",
    "  - **kernel**: Kernel type (try 'rbf', 'linear')\n",
    "- Use GridSearchCV with 5-fold cross-validation\n",
    "- Use 'neg_mean_squared_error' as the scoring metric\n",
    "- Fit on the scaled training data\n",
    "- Display the best parameters and best score\n",
    "- Note: This may take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.7: Train Final SVR Model\n",
    "\n",
    "Evaluate the tuned SVR model:\n",
    "- Extract the best estimator from grid search\n",
    "- Make predictions on the validation set\n",
    "- Inverse transform predictions to original scale\n",
    "- Calculate RMSE, MAE, and R² score\n",
    "- Compare with the baseline model\n",
    "- Report the improvement achieved through tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.8: Final SVR Evaluation on Test Set\n",
    "\n",
    "Evaluate the final SVR model on unseen test data:\n",
    "- Use the best model to predict on the test set\n",
    "- Inverse transform predictions\n",
    "- Calculate and display final test metrics (RMSE, MAE, R²)\n",
    "- Compare test performance with validation performance\n",
    "- Report the mean and standard deviation of the target variable for context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Evaluation - Regression\n",
    "\n",
    "### Step 8.1: Predicted vs Actual Values\n",
    "\n",
    "Visualize model predictions:\n",
    "- Create a scatter plot with actual values on x-axis and predicted values on y-axis\n",
    "- Add a diagonal reference line representing perfect predictions\n",
    "- Format the plot with proper labels and title\n",
    "- Interpret the plot:\n",
    "  - Points close to the line indicate good predictions\n",
    "  - Systematic deviations suggest bias\n",
    "  - Spread around the line indicates variance in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.2: Residual Analysis\n",
    "\n",
    "Analyze prediction errors:\n",
    "- Calculate residuals (actual - predicted)\n",
    "- Create two plots:\n",
    "  1. Residual plot: residuals vs predicted values\n",
    "  2. Histogram of residuals\n",
    "- Check for patterns in the residual plot:\n",
    "  - Random scatter is good (homoscedasticity)\n",
    "  - Patterns suggest model is missing something\n",
    "  - Funnel shape suggests heteroscedasticity\n",
    "- Check if residuals are normally distributed (from histogram)\n",
    "- Calculate and display residual statistics (mean, std, min, max)\n",
    "- Ideally, mean should be close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary and Conclusions\n",
    "\n",
    "### Step 9.1: Comprehensive Performance Summary\n",
    "\n",
    "Create a comprehensive summary of both models:\n",
    "- Summarize classification results:\n",
    "  - Best hyperparameters found\n",
    "  - Test accuracy\n",
    "  - AUC score\n",
    "  - Confusion matrix breakdown\n",
    "- Summarize regression results:\n",
    "  - Best hyperparameters found\n",
    "  - Test RMSE, MAE, R²\n",
    "  - Typical prediction error\n",
    "- Compare both models' performance relative to baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9.2: Business Insights and Recommendations\n",
    "\n",
    "Write a text analysis covering:\n",
    "\n",
    "**Key Findings:**\n",
    "- What did you learn about customer behavior from the classification model?\n",
    "- What factors seem most important for predicting deposits?\n",
    "- How accurate is the balance prediction from regression?\n",
    "\n",
    "**Business Recommendations:**\n",
    "- How should StirBank use the classification model?\n",
    "- Which customers should they prioritize for marketing calls?\n",
    "- What is the cost-benefit trade-off between false positives and false negatives?\n",
    "- Should they consider different strategies for different customer segments?\n",
    "\n",
    "**Model Limitations:**\n",
    "- Where do the models perform poorly?\n",
    "- What assumptions might not hold in practice?\n",
    "- How might model performance degrade over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection Questions\n",
    "\n",
    "Answer the following questions based on your work:\n",
    "\n",
    "1. **Kernel Selection:** How does the RBF kernel differ from the linear kernel? When might you prefer one over the other?\n",
    "\n",
    "2. **Hyperparameter C:** What is the role of the C parameter in SVM? What happens when C is very large? Very small?\n",
    "\n",
    "3. **Feature Scaling:** Why is feature scaling critical for SVM? What would happen if you forgot to scale?\n",
    "\n",
    "4. **Error Trade-offs:** In the classification task, which is worse for the bank: false positives or false negatives? Why?\n",
    "\n",
    "5. **Model Improvements:** Based on your analysis, what are three specific ways you could improve these models?\n",
    "\n",
    "6. **CRISP-DM:** How did following the CRISP-DM framework help structure your analysis? What stages were most important?\n",
    "\n",
    "7. **Practical Deployment:** What challenges might arise when deploying these models in production at StirBank?\n",
    "\n",
    "---\n",
    "**End of Lab 07**\n",
    "\n",
    "### Submission Checklist:\n",
    "- ✅ All code cells executed without errors\n",
    "- ✅ All visualizations displayed correctly\n",
    "- ✅ Results interpreted and explained\n",
    "- ✅ Reflection questions answered\n",
    "- ✅ Business recommendations provided\n",
    "- ✅ Code is well-commented and readable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
